{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                           Escola Politécnica da Universidade de São Paulo\n",
    "                                         Data: 13/09/2019\n",
    "#       PMR3508 - Aprendizado de Máquina e Reconhecimento de Padrões\n",
    "### Análise e aplicação do k-NN a base *adult*\n",
    "#### Autor: Lucas Nunes Sequeira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação dos dados (*Data Prep*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa primeira etapa, começo importando algumas bibliotecas que usaremos ao longo do desenvolvimento do notebook. Além disso, faremos um tratamento nos **dados faltantes** com o uso da biblioteca *pandas*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importação dos dados\n",
    "\n",
    "Agora, subo o arquivo *train_data.csv* através do *pandas* na forma de **DataFrame**, considerando também valores <font color='red'>*?*</font> como <font color='red'>*Nan*</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16280</td>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>204991</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16281</td>\n",
       "      <td>58</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>310085</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16282</td>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>146117</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16283</td>\n",
       "      <td>24</td>\n",
       "      <td>Private</td>\n",
       "      <td>138938</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16284</td>\n",
       "      <td>57</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>258883</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  age     workclass  fnlwgt     education  education.num  \\\n",
       "0  16280   34       Private  204991  Some-college             10   \n",
       "1  16281   58     Local-gov  310085          10th              6   \n",
       "2  16282   25       Private  146117  Some-college             10   \n",
       "3  16283   24       Private  138938  Some-college             10   \n",
       "4  16284   57  Self-emp-inc  258883       HS-grad              9   \n",
       "\n",
       "       marital.status         occupation   relationship   race     sex  \\\n",
       "0            Divorced    Exec-managerial      Own-child  White    Male   \n",
       "1  Married-civ-spouse   Transport-moving        Husband  White    Male   \n",
       "2       Never-married  Machine-op-inspct  Not-in-family  White    Male   \n",
       "3            Divorced       Adm-clerical  Not-in-family  White  Female   \n",
       "4  Married-civ-spouse   Transport-moving        Husband  White    Male   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0             0             0              44  United-States  <=50K  \n",
       "1             0             0              40  United-States  <=50K  \n",
       "2             0             0              42  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4          5178             0              60        Hungary   >50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train_data.csv', na_values = '?')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma do DataFrame: (32560, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Forma do DataFrame:', df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Identificando os **dados faltantes** (*missing data*)\n",
    "\n",
    "Nessa etapa dessa seção, identifico os **dados faltantes** utilizando algumas ferramentas do *pandas*. Para em seguida analisar o tipo, se é aleatório ou não por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>1843</td>\n",
       "      <td>5.660319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>1836</td>\n",
       "      <td>5.638821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native.country</th>\n",
       "      <td>583</td>\n",
       "      <td>1.790541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours.per.week</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total         %\n",
       "occupation       1843  5.660319\n",
       "workclass        1836  5.638821\n",
       "native.country    583  1.790541\n",
       "income              0  0.000000\n",
       "hours.per.week      0  0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending = False)\n",
    "percent = ((df_train.isnull().sum()/df_train.isnull().count())*100).sort_values(ascending = False)\n",
    "missing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que os **dados faltantes** concentram-se em 3 colunas: '*occupation*', '*workclass*' e '*native.country*'. Observo as distribuições das colunas, para analisarmos melhor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occupation:\n",
      "\n",
      "count              30717\n",
      "unique                14\n",
      "top       Prof-specialty\n",
      "freq                4140\n",
      "Name: occupation, dtype: object\n",
      "\n",
      "\n",
      "workclass:\n",
      "\n",
      "count       30724\n",
      "unique          8\n",
      "top       Private\n",
      "freq        22696\n",
      "Name: workclass, dtype: object\n",
      "\n",
      "\n",
      "native.country:\n",
      "\n",
      "count             31977\n",
      "unique               41\n",
      "top       United-States\n",
      "freq              29169\n",
      "Name: native.country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('occupation:\\n')\n",
    "print(df_train['occupation'].describe())\n",
    "\n",
    "print('\\n\\nworkclass:\\n')\n",
    "print(df_train['workclass'].describe())\n",
    "\n",
    "print('\\n\\nnative.country:\\n')\n",
    "print(df_train['native.country'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para os três casos, devido a alta frequência da moda, utilizarei a moda como valor imputado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = df_train['workclass'].describe().top\n",
    "df_train['workclass'] = df_train['workclass'].fillna(value)\n",
    "\n",
    "value = df_train['native.country'].describe().top\n",
    "df_train['native.country'] = df_train['native.country'].fillna(value)\n",
    "\n",
    "value = df_train['occupation'].describe().top\n",
    "df_train['occupation'] = df_train['occupation'].fillna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native.country</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours.per.week</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital.loss</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital.gain</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total    %\n",
       "income              0  0.0\n",
       "native.country      0  0.0\n",
       "hours.per.week      0  0.0\n",
       "capital.loss        0  0.0\n",
       "capital.gain        0  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending = False)\n",
    "percent = ((df_train.isnull().sum()/df_train.isnull().count())*100).sort_values(ascending = False)\n",
    "missing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, agora nosso banco de dados para o treino está limpo e pronto para ser analisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise exploratória dos dados\n",
    "\n",
    "Nessa etapa, utilizarei as bibliotecas: *matplotlib*, *pandas* e *seaborn* como ferramentas para analisarmos e visualizarmos os dados, e assim tirar algumas conclusões sobre os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7fea1c3c74e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "sns.set()\n",
    "sns.pairplot(df_train, vars = cols, hue = 'income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Descrição dos dados\n",
    "\n",
    "Observaremos com o uso da função *.describe()* e *.hist()* do *pandas* para clarear nossas primeiras inferências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De cara observamos que as colunas *capital.gain* e *capital.loss* possuem grupos bem definidos e distantes, para isso, veremos seu histograma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "df_train['capital.gain'].hist(color = 'coral')\n",
    "plt.xlabel('capital gain')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Capital gain histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "df_train['capital.loss'].hist(color = 'coral')\n",
    "plt.xlabel('capital loss')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Capital loss histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo vemos que há uma concentração quase absoluta para valores pequenos, enquanto há poucos, bastante altos. Agora para termos uma noção da curva de idades do banco de dados, avalio com *.hist()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "df_train['age'].hist(color = 'coral')\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Age histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, podemos também avaliar com a função *.distplot()* do *seaborn* para compararmos com uma **curva de distribuição**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.figure(figsize=(13,7))\n",
    "sns.distplot(df_train['age'], color = 'darkorchid', bins = 70)\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Distribution of age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que há uma grande quantidade de jovens (20 a 40 anos) nessa população."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "df_train['hours.per.week'].hist(color = 'coral')\n",
    "plt.xlabel('hours per week')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Hours per week histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluímos também que em maioria (e em média) os indivídos desse banco de dados trabalham 40 horas por semana (8 horas por dia e finais de semana livre) o que é saudável. No entanto, há uma parcela significativa que excede esse número, analiso a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_work = df_train[df_train['hours.per.week'] > 40]\n",
    "plt.figure(figsize=(13, 7))\n",
    "super_work['hours.per.week'].hist(color = 'coral', bins = 5)\n",
    "plt.xlabel('hours per week')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Hours per week histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E esses '*super trabalhadores*' que trabalham acima de 40 horas por semana constituem um grupo que cai exponencialmente com as horas de trabalho, no entanto, vemos por exemplo que em média eles trabalham:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = super_work['hours.per.week'].describe()['mean']\n",
    "print('{0} horas por semana ({1} horas por dia com finais de semana livre). O que é algo que já começa a ser bastante desgastante para o trabalhador.'.format(int(mean), int(mean/5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Comparação dos dados\n",
    "\n",
    "Nessa subseção faremos uma análise comparativa entre os dados dos indivídos do banco de dados. Utilizaremos histogramas, gráficos de pizza e boxplots.\n",
    "\n",
    "Primeiro, crio uma função de comparação para histogramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_histogram(df, obj_var, test_var, obj_labels = None, alpha = 0.7):\n",
    "    \n",
    "    if obj_labels is None:\n",
    "        obj_labels = df[obj_var].unique()\n",
    "    \n",
    "    #obj_var = 'income'\n",
    "    #obj_labels = ['>50K', '<=50K']\n",
    "    #test_var = 'age' (for example)\n",
    "    \n",
    "    temp = []\n",
    "    n_labels = len(obj_labels)\n",
    "    for i in range(n_labels):\n",
    "        temp.append(df[df[obj_var] == obj_labels[i]])\n",
    "        temp[i] = np.array(temp[i][test_var]).reshape(-1,1)\n",
    "\n",
    "    fig = plt.figure(figsize= (13,7))\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        plt.hist(temp[i], alpha = alpha)\n",
    "    plt.xlabel(test_var)\n",
    "    plt.ylabel('quantity')\n",
    "    plt.title('Histogram over \\'' + test_var + '\\' filtered by \\'' + obj_var + '\\'')\n",
    "    plt.legend(obj_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_histogram(df_train, 'income', 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre o histograma acima (*age* e *income*) vemos que há uma distribuição relativamente normal sobre as pessoas que recebem *>50K* com o termo médio próximo de 45 anos; já para pessoas *<=50K* , observa-se que com o aumento da idade, há uma redução na quantidade de pessoas que recebem o valor.\n",
    "\n",
    "Agora, farei uma análise sobre a distribuição de sexo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "df_train['sex'].value_counts().plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que há nos dados, mais homens que mulheres, com relação à esses valores, temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male = qtd sex == Male\n",
    "male = df_train[df_train['sex'] == 'Male'].count()[0]\n",
    "\n",
    "# female = qtd sex == Female\n",
    "female = df_train.shape[0] - male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Temos {0} homens e {1} mulheres, ou seja, apenas {2:3.2f}% são mulheres.\".format(male, female, female*100/(female+male)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_histogram(df_train, 'income', 'sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre o histograma acima, nota-se que há uma grande discrepância percentual (veja os valores abaixo) entre mulheres que recebem *>50K* e homens que recebem o mesmo valor, vemos que há muito mais homens que recebem *>50K*. Esses resultados sugerem que há **desigualdade de gênero** tratando-se do salário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male_income = [qtd > 50K, qtd <= 50K]\n",
    "male_income = []\n",
    "temp = df_train[df_train['sex'] == 'Male']\n",
    "male_income.append(temp[temp['income'] == '>50K'].count()[0])\n",
    "male_income.append(male-male_income[0])\n",
    "\n",
    "# female_income = [qtd > 50K, qtd <= 50K]\n",
    "female_income = []\n",
    "temp = df_train[df_train['sex'] == 'Female']\n",
    "female_income.append(temp[temp['income'] == '>50K'].count()[0])\n",
    "female_income.append(female-female_income[0])\n",
    "\n",
    "# % of male that has >50K income:\n",
    "male_over = male_income[0]/male\n",
    "\n",
    "# % of female that has >50K income:\n",
    "female_over = female_income[0]/female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Temos que dentre os homens, {0:1.2f}% possuem renda anual superior a 50.000, já dentre as mulheres, temos {1:2.2f}% apenas que possuem renda anual superior a 50.000.'.format(male_over*100, female_over*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda sobre a questão de gênero, temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_histogram(df_train, 'sex', 'hours.per.week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que vemos é que existem muito mais homens (inclusive percentualmente) que trabalham mais de 40 horas por semana, e percentualmente vemos mais mulheres trabalhando menos de 30 horas semanais. Agora analisarei as ocupações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = df_train[df_train['sex'] == 'Female']\n",
    "male = df_train[df_train['sex'] == 'Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "male['occupation'].value_counts().plot(kind = 'bar', color = 'purple')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Histogram of male over occupations')\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "female['occupation'].value_counts().plot(kind = 'bar', color = 'coral')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Histogram of female over occupations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que há uma nítida diferença entre a empregabilidade dos homens e das mulheres. Além disso observamos também que não há mulheres que trabalham nas *Armed-Forces*, será uma política exclusiva?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, faremos algumas análises étnicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "df_train['race'].value_counts().plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que vemos é uma concentração bastante elevada da quantidade de pessoas brancas nessa população pesquisada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_histogram(df_train, 'income', 'race')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o histograma acima, podemos de cara visualizar que provavelmente há um percentual maior de pessoas brancas que recebem mais do 50.000 sobre as pessoas negras, amer-indian-eskimo e outros. Os valores seguem abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kind = qtd race == 'unique'\n",
    "white = df_train[df_train['race'] == 'White'].count()[0]\n",
    "black = df_train[df_train['race'] == 'Black'].count()[0]\n",
    "amer = df_train[df_train['race'] == 'Amer-Indian-Eskimo'].count()[0]\n",
    "other = df_train[df_train['race'] == 'Other'].count()[0]\n",
    "asian = df_train[df_train['race'] == 'Asian-Pac-Islander'].count()[0]\n",
    "\n",
    "# kind_income = [qtd > 50K, qtd <= 50K]\n",
    "white_income = []\n",
    "temp = df_train[df_train['race'] == 'White']\n",
    "white_income.append(temp[temp['income'] == '>50K'].count()[0])\n",
    "white_income.append(white-white_income[0])\n",
    "\n",
    "black_income = []\n",
    "temp = df_train[df_train['race'] == 'Black']\n",
    "black_income.append(temp[temp['income'] == '>50K'].count()[0])\n",
    "black_income.append(black-black_income[0])\n",
    "\n",
    "amer_income = []\n",
    "temp = df_train[df_train['race'] == 'Amer-Indian-Eskimo']\n",
    "amer_income.append(temp[temp['income'] == '>50K'].count()[0])\n",
    "amer_income.append(amer-amer_income[0])\n",
    "\n",
    "asian_income = []\n",
    "temp = df_train[df_train['race'] == 'Asian-Pac-Islander']\n",
    "asian_income.append(temp[temp['income'] == '>50K'].count()[0])\n",
    "asian_income.append(asian-asian_income[0])\n",
    "\n",
    "other_income = []\n",
    "temp = df_train[df_train['race'] == 'Other']\n",
    "other_income.append(temp[temp['income'] == '>50K'].count()[0])\n",
    "other_income.append(other-other_income[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Brancos:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(white_income[0]*100/white))\n",
    "print('Negros:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(black_income[0]*100/black))\n",
    "print('Amer-Indian-Eskimo:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(amer_income[0]*100/amer))\n",
    "print('Asian-Pac-Islander:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(asian_income[0]*100/asian))\n",
    "print('Outros:\\n   {0:1.2f}% recebem mais de 50.000'.format(other_income[0]*100/other))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disso podemos concluir, que há também uma certa **desigualdade racial**, em que etinias não descrita em *Others*, e as etnias *Black* e *Amer-Indian-Eskimo* recebem proporcionalmente menos que as demais. Em seguida, comparemos as duas etinias em maior quantidade (brancos e negros), com relação às ocupações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = df_train[df_train['race'] == 'White']\n",
    "black = df_train[df_train['race'] == 'Black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "white['occupation'].value_counts().plot(kind = 'bar', color = 'purple')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Histogram of white people over occupations')\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "black['occupation'].value_counts().plot(kind = 'bar', color = 'coral')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Histogram of black people over occupations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente vemos que há uma grande diferença entre as ocupações para cada etnia. Além disso podemos fazer uma comparação sobre a educação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = 'race'\n",
    "var2 = 'education.num'\n",
    "\n",
    "data = pd.concat([df_train[var2], df_train[var1]], axis=1)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "sns.boxplot(x=var1, y=var2, data=data, notch = True)\n",
    "plt.title('Boxplot of education num over race')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos novamente, brancos e Asian-Pac-Islander, com uma educação em média superior às demais etnias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, analisaremos os salários das ocupações, para tirarmos mais conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_50k = df_train[df_train['income'] == '>50K']\n",
    "under_50k = df_train[df_train['income'] == '<=50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "over_50k['occupation'].value_counts().plot(kind = 'bar', color = 'purple')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Histogram of income over 50K over occupations')\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "under_50k['occupation'].value_counts().plot(kind = 'bar', color = 'coral')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Histogram of income under 50K over occupations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que aqueles que recebem acima de 50.000 em maioria são *Exec-managerial*, seguido por *Prof-specialty*, que são ocupações ocupadas em maioria por homens brancos. Já aqueles que recebem menos de 50.000 ocupam em maioria *Adm-clerical*, *Craft-repair*, *Other-service* e *Sales*, que são áreas que empregam maioria mulheres e negros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma análise também interessante é sobre as idades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2 = 'age'\n",
    "var1 = 'hours.per.week'\n",
    "\n",
    "data = pd.concat([df_train[var2], df_train[var1]], axis=1)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(14, 15))\n",
    "\n",
    "sns.boxplot(x=var1, y=var2, data=data, orient = 'h')\n",
    "plt.title('Boxplot of age over hours per week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vemos que pessoas muito jovens trabalham em média menos de 40 horas por semana, provavelmente pois devem trabalhar meio período. Assim como pessoas mais idosas, em média trabalham também menos de 40 horas por dia.\n",
    "\n",
    "Uma outra avaliação é sobre a quantidade de tempo de trabalho por semana com relação ao nível de educação das pessoas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2 = 'education'\n",
    "var1 = 'hours.per.week'\n",
    "\n",
    "data = pd.concat([df_train[var2], df_train[var1]], axis=1)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(13, 7))\n",
    "#ax.set_ylim(0,10000)\n",
    "\n",
    "order = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th',\n",
    "         '11th', '12th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc',\n",
    "         'Some-college', 'Bachelors', 'Masters', 'Doctorate']\n",
    "sns.boxplot(x=var1, y=var2, data=data, order = order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que as pessoas com os maiores níveis de educação, normalmente trabalham mais de 40 horas por dia, como aqueles que possuem título de doutorado, mestrado e bacharel; como também os que concluiram uma escola profissionalizante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análise e preprocessamento dos atributos\n",
    "\n",
    "Nessa seção usaremos bibliotecas como *skitlearn* para fazermos alguns preprocessamento dos dados, como também algumas análises de correlação entre os atributos para otimizarmos nosso aprendizado de máquina no futuro. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Tratamento dos atributos\n",
    "\n",
    "Agora, farei um tratamento sobre alguns dos atributos qualitativos e quantitativos de forma a numerar aqueles ordenáveis por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Alguns tratamentos de dados\n",
    "\n",
    "referência: https://www.rdocumentation.org/packages/arules/versions/1.6-3/topics/Adult\n",
    "\n",
    "*education*\n",
    "\n",
    "- qualitativo ordenado\n",
    "    - Preschool < 1st-4th < 5th-6th < 7th-8th < 9th < 10th < 11th < 12th < HS-grad < Prof-school < Assoc-acdm < Assoc-voc < Some-college < Bachelors < Masters < Doctorate\n",
    "    \n",
    "*workclass*\n",
    "\n",
    "- booleano\n",
    "    - isPrivate\n",
    "    \n",
    "*age*\n",
    " *   \n",
    "- quantitativo ordenado\n",
    "     - Young (0-25) < Middle-aged (26-45) < Senior (46-65) < Old (66+)\n",
    "     \n",
    "*hours.per.week*\n",
    "\n",
    "- quantitativo ordenado\n",
    "    - Part-time (0-25) < Full-time (25-40) < Over-time (40-60) < Too-much (60+).\n",
    "\n",
    "*capital.gain* e *capital.loss*\n",
    "\n",
    "- quantitativo ordenado\n",
    "    - None (0) < Low (0 - mediana dos valores maiores que zero) and High (> mediana dos valores maiores que zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vou dividir os atributos quantitativos e qualitativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quatitative_columns = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "qualitative_columns = ['Id', 'education', 'marital.status', 'occupation', 'relationship', 'race',\n",
    "                       'sex', 'native.country', 'income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Funções\n",
    "\n",
    "Algumas declarações de funções para o tratamento dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isprivate(value):\n",
    "    if value == 'Private':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def catg(value, categories, ordenation = None):\n",
    "    if ordenation is not None:\n",
    "        ordenation = np.arange(0, len(categories))\n",
    "    for pos in ordenation:\n",
    "        if value == categories[pos]:\n",
    "            return pos\n",
    "    return -1\n",
    "\n",
    "def equals(value, x):\n",
    "    for v in x:\n",
    "        if v == value:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 *workclass*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base['workclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# privado: 1 se trabalha para o privado, 0 caso contrario\n",
    "private = pd.DataFrame({'private': base['workclass'].apply(isprivate)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 *native.country*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['native.country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usa: 1 se é sul_global, 0 caso contrário\n",
    "countries = ['Mexico', 'Philippines', 'Puerto-Rico', 'El-Salvador', 'India', 'Cuba', 'Jamaica',\n",
    "             'South', 'China', 'Dominican-Republic', 'Vietnam', 'Guatemala', 'Columbia', 'Taiwan',\n",
    "             'Haiti', 'Iran', 'Nicaragua', 'Peru', 'Ecuador', 'Trinadad&Tobago', 'Cambodia',\n",
    "             'Laos', 'Thailand', 'Yugoslavia', 'Outlying-US(Guam-USVI-etc)', 'Honduras']\n",
    "sul_global = pd.DataFrame({'sul.global': base['native.country'].apply(equals, args = [countries])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5 *education*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preschool < 1st-4th < 5th-6th < 7th-8th < 9th < 10th < 11th < 12th < HS-grad < Prof-school < Assoc-acdm < Assoc-voc < Some-college < Bachelors < Masters < Doctorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_order = [15, 11, 5, 12, 10, 1, 14, 7, 2, 8, 4, 13, 0, 3, 6, 9]\n",
    "args = [base['education'].unique(), edu_order]\n",
    "education_classes = pd.DataFrame({'education.classes': base['education'].apply(catg, args = args)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.6 *hours.per.week*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.cut(base['hours.per.week'], bins = [-1, 25, 40, 60, 200], labels = [0, 1, 2, 3])\n",
    "hours_per_week_clusters = pd.DataFrame({'hours.per.week.clusters': aux})\n",
    "hours_per_week_clusters = hours_per_week_clusters.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.7 *capital.gain* e *capital.loss*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.median(base[base['capital.gain'] > 0]['capital.gain'])\n",
    "aux = pd.cut(base['capital.gain'],\n",
    "             bins = [-1, 0, median, base['capital.gain'].max()+1],\n",
    "             labels = [0, 1, 2])\n",
    "capital_gain_clusters = pd.DataFrame({'capital.gain.clusters': aux})\n",
    "capital_gain_clusters = capital_gain_clusters.astype(np.int)\n",
    "\n",
    "median = np.median(base[base['capital.loss'] > 0]['capital.loss'])\n",
    "aux = pd.cut(base['capital.loss'],\n",
    "             bins = [-1, 0, median, base['capital.loss'].max()+1],\n",
    "             labels = [0, 1, 2])\n",
    "capital_loss_clusters = pd.DataFrame({'capital.loss.clusters': aux})\n",
    "capital_loss_clusters = capital_loss_clusters.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([sul_global, private, education_classes, \n",
    "                      hours_per_week_clusters, capital_gain_clusters, \n",
    "                      capital_loss_clusters], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, construimos essa pequena tabela de dados que podem vir a ser uteis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aux = base['income'].apply(equals, args = [['>50K']])\n",
    "\n",
    "aux = pd.concat([new_data, pd.DataFrame({'income': aux})], axis = 1)\n",
    "\n",
    "new = aux.astype(np.int)\n",
    "aux.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, uma simples visualização com uma matriz de correlação para termos uma ideia das contribuições sobre *income*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = aux.corr()\n",
    "corr_mat\n",
    "sns.set()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_mat, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Transformações de outros dados e ajuste da tabela\n",
    "\n",
    "Para dar início à análise dos atributos, tornarei numéricas os atributos classificatórios, para podermos usá-los de forma mais eficiente.\n",
    "\n",
    "\n",
    "*Obs: antes eu removo a coluna 'Id' pois é totalmente aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "base = base.drop(['Id', 'education', 'capital.loss', 'capital.gain'], axis = 1)\n",
    "base.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis classificatórias:\n",
    "1. workclass\n",
    "2. marital.status\n",
    "3. occupation\n",
    "4. relationship\n",
    "5. race\n",
    "6. sex\n",
    "7. native.country\n",
    "8. income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, utilizo o LabelEncoder para transformar as variáveis classificatórias em números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['workclass', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "base['income'] = label_encoder_y.fit_transform(base['income'])\n",
    "\n",
    "label_encoder_x = LabelEncoder()\n",
    "for name in var:\n",
    "    base[name] = label_encoder_x.fit_transform(base[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Junção da base com os valores construídos e seleção de alguns atributos por intuição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.concat([new_data, base], axis = 1)\n",
    "base = base.drop(['marital.status',  'relationship', 'fnlwgt', 'hours.per.week'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Matriz de correlação\n",
    "\n",
    "Agora, farei uma análise sobre a correlação entre os atributos, para isso utilizarei da matriz de correlação do próprio **DataFrame** associado ao *seaborn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aux = base.astype(np.int)\n",
    "\n",
    "corr_mat = aux.corr()\n",
    "f, ax = plt.subplots(figsize=(20, 13))\n",
    "sns.heatmap(corr_mat, vmax=.7, square=True, cmap=\"coolwarm\", annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Remoção de atributos pouco relevantes\n",
    "\n",
    "Utilizo a matriz de correlação acima, para visualisar e reduzir a dimenção do problema excluindo atributos pouco relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unselected_columns = []\n",
    "unselected_columns.append('workclass')\n",
    "unselected_columns.append('native.country')\n",
    "unselected_columns.append('occupation')\n",
    "unselected_columns.append('education.classes')\n",
    "unselected_columns.append('race')\n",
    "unselected_columns.append('sul.global')\n",
    "\n",
    "\n",
    "base = base.drop(unselected_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = base.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = aux.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corr_mat, vmax=.7, square=True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Agrupamento por K-NN\n",
    "\n",
    "Nessa última etapa, utilizarei a biblioteca *sklearn* para utilização do método de aprendizado **k-NN**. Nesse processo, farei o uso da **validação cruzada** para avaliar o desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Escalonamento dos dados\n",
    "\n",
    "Primeiro farei um tratamento sobre os dados, de forma a escaloná-los utilizando *StandardScaler*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base.drop(['income'], axis = 1)\n",
    "y = base['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = StandardScaler()\n",
    "\n",
    "X = scaler_x.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Definição do hiperparâmetro k do k-NN\n",
    "\n",
    "Primeiro, avaliaremos o comportamento do aprenzidado para k = 1, ..., 29 para que possamos identificar o melhor valor de k para utilizarmos para prever os valores da base de teste a ser importada. Essa avaliação, será feita com a utilização da validação cruzada com 5 *folds*, e assim será possível determinar o melhor hiperparâmetro k que se aplicará ao nosso problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_mean = []\n",
    "scores_std = []\n",
    "\n",
    "k_lim_inf = 1\n",
    "k_lim_sup = 30\n",
    "\n",
    "folds = 5\n",
    "\n",
    "k_max = None\n",
    "max_acc = 0\n",
    "\n",
    "i = 0\n",
    "print('Finding best k...')\n",
    "for k in range(k_lim_inf, k_lim_sup):\n",
    "    \n",
    "    KNNclf = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    score = cross_val_score(KNNclf, X, y, cv = folds)\n",
    "    \n",
    "    scores_mean.append(score.mean())\n",
    "    scores_std.append(score.std())\n",
    "    \n",
    "    if scores_mean[i] > max_acc:\n",
    "        k_max = k\n",
    "        max_acc = scores_mean[i]\n",
    "    i += 1\n",
    "    if not (k%3):\n",
    "        print('   K = {0} | Best CV acc = {1:2.2f}% (best k = {2})'.format(k, max_acc*100, k_max))\n",
    "print('\\nBest k: {}'.format(k_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.errorbar(np.arange(k_lim_inf, k_lim_sup), scores_mean, scores_std,\n",
    "             marker = 'o', markerfacecolor = 'purple' , linewidth = 3,\n",
    "             markersize = 10, color = 'coral', ecolor = 'purple', elinewidth = 1.5)\n",
    "\n",
    "\n",
    "yg = []\n",
    "x = np.arange(0, k_lim_sup+1)\n",
    "for i in range(len(x)):\n",
    "    yg.append(max_acc)\n",
    "plt.plot(x, yg, '--', color = 'purple', linewidth = 1)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('KNN performed on several values of k')\n",
    "plt.axis([0, k_lim_sup, min(scores_mean) - max(scores_std), max(scores_mean) + 1.5*max(scores_std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima vemos o gráfico dos erros médios sobre a validação cruzada para diferentes valores de k, em que foi possível determinar o melhor k que satisfaz nosso problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Treinamento do k-NN\n",
    "\n",
    "Agora, faremos o treinamento do k-NN utilizando nossa base de treino, em seguida inferimos sobre nossa acurácia da base de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k_max\n",
    "\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=k, p = 1)\n",
    "KNNclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predição dos valores sem classe\n",
    "\n",
    "Nessa última etapa, utilizaremos o nosso classificador treinado para predizer sobre as classes do banco de dados teste que não possui valor de classe atribuído aos indivíduos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_data.csv', na_values='?')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Adição das colunas extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# privado: 1 se trabalha para o privado, 0 caso contrario\n",
    "private = pd.DataFrame({'private': df_test['workclass'].apply(isprivate)})\n",
    "\n",
    "# usa: 1 se é sul_global, 0 caso contrário\n",
    "countries = ['Mexico', 'Philippines', 'Puerto-Rico', 'El-Salvador', 'India', 'Cuba', 'Jamaica',\n",
    "             'South', 'China', 'Dominican-Republic', 'Vietnam', 'Guatemala', 'Columbia', 'Taiwan',\n",
    "             'Haiti', 'Iran', 'Nicaragua', 'Peru', 'Ecuador', 'Trinadad&Tobago', 'Cambodia',\n",
    "             'Laos', 'Thailand', 'Yugoslavia', 'Outlying-US(Guam-USVI-etc)', 'Honduras']\n",
    "sul_global = pd.DataFrame({'sul.global': df_test['native.country'].apply(equals, args = [countries])})\n",
    "\n",
    "# hours.per.week.cluster\n",
    "aux = pd.cut(df_test['hours.per.week'], bins = [-1, 25, 40, 60, 200], labels = [0, 1, 2, 3])\n",
    "hours_per_week_clusters = pd.DataFrame({'hours.per.week.clusters': aux})\n",
    "hours_per_week_clusters = hours_per_week_clusters.astype(np.int)\n",
    "\n",
    "# capital.gain.cluster\n",
    "median = np.median(df_test[df_test['capital.gain'] > 0]['capital.gain'])\n",
    "aux = pd.cut(df_test['capital.gain'],\n",
    "             bins = [-1, 0, median, df_test['capital.gain'].max()+1],\n",
    "             labels = [0, 1, 2])\n",
    "capital_gain_clusters = pd.DataFrame({'capital.gain.clusters': aux})\n",
    "capital_gain_clusters = capital_gain_clusters.astype(np.int)\n",
    "\n",
    "# capital.loss.cluster\n",
    "median = np.median(df_test[df_test['capital.loss'] > 0]['capital.loss'])\n",
    "aux = pd.cut(df_test['capital.loss'],\n",
    "             bins = [-1, 0, median, df_test['capital.loss'].max()+1],\n",
    "             labels = [0, 1, 2])\n",
    "capital_loss_clusters = pd.DataFrame({'capital.loss.clusters': aux})\n",
    "capital_loss_clusters = capital_loss_clusters.astype(np.int)\n",
    "\n",
    "new_data = pd.concat([sul_global, private, hours_per_week_clusters,\n",
    "                      capital_gain_clusters, capital_loss_clusters], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'education.num', 'sex']\n",
    "\n",
    "base_test = pd.concat([new_data, df_test[features]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = base_test.isnull().sum().sort_values(ascending = False)\n",
    "percent = ((base_test.isnull().sum()/base_test.isnull().count())*100).sort_values(ascending = False)\n",
    "missing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro ajustamos os dados para eles estarem de acordo com o formado do treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test['sex'] = base['sex'].apply(equals, args = [['Male']])\n",
    "X_prev = scaler_x.transform(base_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfim, predizemos as classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = KNNclf.predict(X_prev)\n",
    "\n",
    "temp = label_encoder_y.inverse_transform(temp)\n",
    "temp = {'income': temp}\n",
    "predicts = pd.DataFrame(temp)\n",
    "\n",
    "predictions = pd.concat([df_test['Id'], predicts], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, escrevo os resultados em **submission.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
